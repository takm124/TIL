[TOC]



# CHAPTER3 - OS 캐시와 분산

## 강의 8 OS의 캐시 구조

- OS에는 디스크 내의 데이터를 빠르게 액세스할 수 있도록 하는 구조가 갖춰져 있다.
  - 이게 캐시다
  - Linux의 경우 페이지 캐시라고 하는데 페이지가 무엇인지 알아보자

<Br>

- 물리적인 하드웨어를 OS에서 추상화하기 위해 가상 메모리 구조가 존재한다.
  - 프로세스에서 메모리를 다루기 쉽게 하는 이점을 제공한다 (주소가 0x000부터 시작한다)
  - OS가 커널 내에서 메모리를 추상화하고 있다.
  - 페이지 : OS가 물리 메모리를 확보/관리하는 단위
  - 페이지는 가상 메모리의 최소단위

<br>

- Linux의 페이지 캐시 원리
  - 디스크의 내용을 일단 메모리에 읽어들임
  - 작성된 페이지는 파기되지 않고 남음 (페이지 캐시)
  - 예외의 경우를 제외하고 모든 I/O에 투과적으로 작용됨 (디스크의 캐시를 담당하는 곳, VFS)

<Br>

- VFS(Virtual File System)
  - 디스크를 조작하는 디바이스 드라이버와 OS 사이에 끼어있는 파일 시스템
  - 어떤 디스크를 읽더라도 동일한 구조로 캐싱된다.

<br>

- 리눅스에서는 sar, 윈도우에서는 perfmon으로 os 지표 확인 가능

<br>

## 강의 9 I/O 부하를 줄이는 방법

- 캐시를 전제로 한 I/O 줄이는 방법
  - 앞선 강의에서 언급했듯, 캐시를 전제로 I/O를 줄이기 위한 대책을 세워가는 것이 유효하다.
  - 데이터 규모에 비해 물리 메모리가 크면 전부 캐싱할 수 있다.
  - 경제적 비용과의 밸런스를 고려해야 한다.

<br>

- 캐시로 해결될 수 없는 규모면 복수 서버로 확장을 시켜야 한다.
  - AP 서버를 늘리면 CPU 부하를 낮출 수 있다.
  - DB 서버를 늘려야 할 떄는 반드시 부하 떄문만은 아니고 오히려 캐시 용량을 늘리고자 할 때 혹은 효율을 높이고자 할 때인 경우가 많다.
  - 그러나 단순히 대수를 늘리는 것은 효과가 없다.
    - 캐싱할 수 없는 비율은 변함없이 그대로이기 때문

<br>

## 강의 10 국소성을 살리는 분산

- 국소성을 고려한 분산이란?
  - 액세스 패턴을 고려한 분산이다.
    - 액세스 패턴에 따라 저장하는 서버가 달라진다.
  - 캐싱할 수 없는 부분이 사라진다.

<br>

- 파티셔닝
  - 한 대였던 DB 서버를 여러 대의 서버로 분할하는 방법
  - 가장 간단한 것은 테이블 단위 분할
  - 용도별로 시스템을 '섬'으로 나눈다.

<br>

- 요청 패턴을 '섬'으로 분할
  - 요청 URL을 보고 섬을 나눈다 (섬1, 섬2, 섬3 ....)
  - 어떻게 요청이 왔느냐에 따라 접근할 수 있는 방식을 달리 하는 것
  - 의외로 봇 엑세스가 많다.

<br>

- 페이지 캐시를 고려한 운용의 기본 규칙
  - OS 기동 직후에 서버를 투입하지 않는다.
    - 자주 사용하는 DB 파일을 cat 해준뒤 로드밸런서에 편입시킨다.
  - 성능 평가는 캐시가 최적화되었을때 진행한다.

<br>

- 부하 분산 이해를 위한 OS 지식
  - OS 캐시
  - 멀티스레드나 멀티프로세스
  - 가상 메모리 구조
  - 파일시스템